{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydataset\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punchline: is our model better than the model that just predicts the average?\n",
    "\n",
    "The best model we can make with no additional information: $\\hat{y} = \\bar{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline comes from train split!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup / Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(actual, predicted):\n",
    "    return actual - predicted\n",
    "\n",
    "def sse(actual, predicted):\n",
    "    return (residuals(actual, predicted) ** 2).sum()\n",
    "\n",
    "def mse(actual, predicted):\n",
    "    n = actual.shape[0]\n",
    "    return sse(actual, predicted) / n\n",
    "\n",
    "def rmse(actual, predicted):\n",
    "    return math.sqrt(mse(actual, predicted))\n",
    "\n",
    "def ess(actual, predicted):\n",
    "    return ((predicted - actual.mean()) ** 2).sum()\n",
    "\n",
    "def tss(actual):\n",
    "    return ((actual - actual.mean()) ** 2).sum()\n",
    "\n",
    "def r2_score(actual, predicted):\n",
    "    return ess(actual, predicted) / tss(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(actual, predicted):\n",
    "    residuals = actual - predicted\n",
    "    plt.hlines(0, actual.min(), actual.max(), ls=':')\n",
    "    plt.scatter(actual, residuals)\n",
    "    plt.ylabel('residual ($y - \\hat{y}$)')\n",
    "    plt.xlabel('actual value ($y$)')\n",
    "    plt.title('Actual vs Residual')\n",
    "    return plt.gca()\n",
    "\n",
    "def regression_errors(actual, predicted):\n",
    "    return pd.Series({\n",
    "        'sse': sse(actual, predicted),\n",
    "        'ess': ess(actual, predicted),\n",
    "        'tss': tss(actual),\n",
    "        'mse': mse(actual, predicted),\n",
    "        'rmse': rmse(actual, predicted),\n",
    "        'r2': r2_score(actual, predicted),\n",
    "    })\n",
    "\n",
    "def baseline_mean_errors(actual):\n",
    "    predicted = actual.mean()\n",
    "    return {\n",
    "        'sse': sse(actual, predicted),\n",
    "        'mse': mse(actual, predicted),\n",
    "        'rmse': rmse(actual, predicted),\n",
    "    }\n",
    "\n",
    "def better_than_baseline(actual, predicted):\n",
    "    sse_baseline = sse(actual, actual.mean())\n",
    "    sse_model = sse(actual, predicted)\n",
    "    return sse_model < sse_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pydataset.data('tips')\n",
    "model = LinearRegression().fit(tips[['total_bill']], tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the fit model on new data\n",
    "new_data = pd.Series([10, 20], name='total_bill').values.reshape(-1, 1)\n",
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = tips.tip\n",
    "predicted = model.predict(tips[['total_bill']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearRegression().fit(tips[['size']], tips.tip)\n",
    "predicted2 = model2.predict(tips[['size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_errors(actual, predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_errors(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_errors(actual, predicted)['sse'] < regression_errors(actual, predicted2)['sse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_than_baseline(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'model 1 (tip ~ total_bill)': regression_errors(actual, predicted),\n",
    "    'model 2 (tip ~ size)': regression_errors(actual, predicted2),\n",
    "    'baseline model': regression_errors(actual, np.repeat(actual.mean(), actual.shape[0]))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidenote: comparing our r2 to sklearn's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_r2 = sklearn.metrics.r2_score(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_r2 = r2_score(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_r2 == sklearn_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_r2, sklearn_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(our_r2, sklearn_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('our mse', mse(actual, predicted))\n",
    "print('sklearn', sklearn.metrics.mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = pydataset.data('mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(mpg[['displ']], mpg.hwy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = mpg.hwy # y\n",
    "predicted = model.predict(mpg[['displ']]) # yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_errors(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_than_baseline(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.scatter(mpg.displ, mpg.hwy, label='actual')\n",
    "ax.scatter(mpg.displ, predicted, label='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidenote: visualizing residuals w/ multiple independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mpg.hwy, actual - predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(actual - predicted, bins=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
