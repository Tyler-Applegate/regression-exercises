{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from env import host, user, password\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is connecting. to the Codeup databse\n",
    "# running a SQL query to return appropriate data from telco_churn\n",
    "# checking to see if csv file exists, and creating one if not\n",
    "# from now on, I'll be able to connect to a csv instead of the Codeup database\n",
    "df = wrangle.get_telco_regression()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does it look like?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do I need to change?\n",
    "# total charges to float\n",
    "# this replaces whitespace with NaN values\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what do I have?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am chosing to drop the 10 obsevations w/ null values\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting total charges to float\n",
    "df['total_charges'] = df['total_charges'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last check of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all together in a function...\n",
    "def wrangle_telco():\n",
    "    '''\n",
    "    This function uses my login credentials to connect to the telco_churn dataset on \n",
    "    Codeup database. It uses a SQL query to return the 'customer_id', 'monthly_charges', \n",
    "    'tenure', and 'total_charges' of all customers with a 2 year contract. It also checks\n",
    "    to see if there is an existing csv file, and if not, writes the database to a csv, to\n",
    "    optimize speed.\n",
    "    '''\n",
    "    df = get_telco_regression()\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df = df.dropna()\n",
    "    df['total_charges'] = df['total_charges'].astype(float)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see if my function(s) are built on top of each other correctly\n",
    "# in order for this to work properly, need to restart kernal\n",
    "# and just run imports, then this cell\n",
    "df = wrangle.wrangle_telco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the same as before?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises III - Challenge\n",
    "Let's set up an example scenario as perspective for our regression exercises using the Zillow dataset.\n",
    "\n",
    "As a Codeup data science graduate, you want to show off your skills to the Zillow data science team in hopes of getting an interview for a position you saw pop up on LinkedIn. You thought it might look impressive to build an end-to-end project in which you use some of their Kaggle data to predict property values using some of their available features; who knows, you might even do some feature engineering to blow them away. Your goal is to predict the values of single unit properties using the obervations from 2017.\n",
    "\n",
    "In these exercises, you will complete the first step toward the above goal: acquire and prepare the necessary Zillow data from the zillow database in the Codeup database server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Acquire bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, and fips from the zillow database for all 'Single Family Residential' properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2152863 entries, 0 to 2152862\n",
      "Data columns (total 8 columns):\n",
      " #   Column                        Non-Null Count    Dtype  \n",
      "---  ------                        --------------    -----  \n",
      " 0   Unnamed: 0                    2152863 non-null  int64  \n",
      " 1   bedroomcnt                    2152852 non-null  float64\n",
      " 2   bathroomcnt                   2152852 non-null  float64\n",
      " 3   calculatedfinishedsquarefeet  2144379 non-null  float64\n",
      " 4   taxvaluedollarcnt             2152370 non-null  float64\n",
      " 5   yearbuilt                     2143526 non-null  float64\n",
      " 6   taxamount                     2148421 non-null  float64\n",
      " 7   fips                          2152863 non-null  float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 131.4 MB\n"
     ]
    }
   ],
   "source": [
    "zillow = wrangle.get_zillow_data()\n",
    "zillow.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using your acquired Zillow data, walk through the summarization and cleaning steps in your wrangle.ipynb file like we did above. You may handle the missing values however you feel is appropriate and meaninful; remember to document your process and decisions using markdown and code commenting where helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any null values/whitespaces?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Store all of the necessary functions to automate your process from acquiring the data to returning a cleaned dataframe witn no missing values in your wrangle.py file. Name your final function wrangle_zillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
